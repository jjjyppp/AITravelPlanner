// src/components/SpeechRecognition.jsx
import React, { useState, useRef, useEffect } from 'react';
import XunfeiSpeechService from '../services/xunfeiSpeechService';
import './SpeechRecognition.css';

const SpeechRecognition = ({ 
  onResult, 
  onError, 
  placeholder = "ç‚¹å‡»å¼€å§‹è¯­éŸ³è¾“å…¥...",
  disabled = false,
  className = ""
}) => {
  const [isListening, setIsListening] = useState(false);
  const [errorMessage, setErrorMessage] = useState('');
  const [audioLevel, setAudioLevel] = useState(0);
  const [isTestingMic, setIsTestingMic] = useState(false);
  const [testMicLevel, setTestMicLevel] = useState(0);
  const [result, setResult] = useState(''); // ä»…ç”¨äºç•Œé¢æ˜¾ç¤º
  
  const audioContextRef = useRef(null);
  const isStoppingRef = useRef(false);
  const audioProcessorRef = useRef(null);
  const audioSourceRef = useRef(null);
  const streamRef = useRef(null);
  const finalResultRef = useRef(''); // ç´¯ç§¯çš„æœ€ç»ˆç»“æœï¼ˆä¸ä¼ é€’ç»™çˆ¶ç»„ä»¶ï¼‰
  const interimResultRef = useRef(''); // ä¸´æ—¶ä¸­é—´ç»“æœ
  const audioBufferRef = useRef([]);
  const sendTimerRef = useRef(null);
  const silenceTimerRef = useRef(null);
  const lastAudioTimeRef = useRef(0);
  const sessionStartTimeRef = useRef(0);
  
  const speechServiceRef = useRef(null);

  // åˆå§‹åŒ–è¯­éŸ³æœåŠ¡
  useEffect(() => {
    speechServiceRef.current = new XunfeiSpeechService();
    
    return () => {
      stopListening();
    };
  }, []);

  // è®¾ç½®è¯­éŸ³æœåŠ¡å›è°ƒ
  useEffect(() => {
    if (!speechServiceRef.current) return;

    speechServiceRef.current.setCallbacks({
      onMessage: (data) => {
        try {
          // ä¸å†å› ä¸ºæ”¶åˆ°ç»“æŸå¸§è€Œè‡ªåŠ¨åœæ­¢å½•éŸ³ï¼Œå®Œå…¨ç”±ç”¨æˆ·æ‰‹åŠ¨æ§åˆ¶
          if (XunfeiSpeechService.isEndFrame(data)) {
            console.log('æ”¶åˆ°æœåŠ¡ç«¯ç»“æŸå¸§ï¼Œä½†ä¸ä¼šè‡ªåŠ¨åœæ­¢å½•éŸ³');
            return;
          }
          
          const recognitionResult = XunfeiSpeechService.processRecognitionResult(data);
          if (recognitionResult) {
            // å¤„ç†è¯†åˆ«ç»“æœç´¯ç§¯ï¼ˆä¸ä¼ é€’ç»™çˆ¶ç»„ä»¶ï¼‰
            handleRecognitionResult(data, recognitionResult);
          }
        } catch (err) {
          console.error('è®¯é£è¯†åˆ«é”™è¯¯:', err);
          const errorMsg = 'è¯­éŸ³è¯†åˆ«é”™è¯¯: ' + err.message;
          setErrorMessage(errorMsg);
          onError && onError(new Error(errorMsg));
        }
      },
      onError: (error) => {
        console.error('WebSocketé”™è¯¯:', error);
        const errorMsg = 'è¿æ¥è®¯é£æœåŠ¡å¤±è´¥: ' + (error.message || 'æœªçŸ¥é”™è¯¯');
        setErrorMessage(errorMsg);
        onError && onError(new Error(errorMsg));
        // stopListening();
      },
      onClose: () => {
        if (!isStoppingRef.current) {
          console.log('WebSocketè¿æ¥å…³é—­');
          // stopListening();
        }
      }
    });
  }, [onResult, onError]);

  // å¤„ç†è¯†åˆ«ç»“æœç´¯ç§¯
  const handleRecognitionResult = (data, recognitionResult) => {
    // ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„recognitionResultä½œä¸ºè¯†åˆ«æ–‡æœ¬
    const text = recognitionResult || data.text || (data.payload && data.payload.result && data.payload.result.text) || '';
    const status = data.status || (data.payload && data.payload.result && data.payload.result.status) || 0;
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç»“æœï¼ˆstatus === 2ï¼‰
    const isFinalResult = status === 2;
    
    if (isFinalResult) {
      // æœ€ç»ˆç»“æœï¼šå°†ä¸­é—´ç»“æœç´¯ç§¯åˆ°æœ€ç»ˆç»“æœä¸­
      if (interimResultRef.current) {
        finalResultRef.current = finalResultRef.current || '';
        finalResultRef.current += interimResultRef.current;
        interimResultRef.current = ''; // æ¸…ç©ºä¸­é—´ç»“æœ
      }
      // æ·»åŠ å½“å‰æœ€ç»ˆç»“æœ
      finalResultRef.current = (finalResultRef.current || '') + text;
      
      // æ›´æ–°UIæ˜¾ç¤º
      setResult(finalResultRef.current);
      
      console.log('ç´¯ç§¯æœ€ç»ˆç»“æœ:', finalResultRef.current);
      
      // ä¸å†å®æ—¶æ›´æ–°çˆ¶ç»„ä»¶ï¼Œåªåœ¨stopListeningæ—¶ä¼ é€’æœ€ç»ˆç»“æœ
    } else {
      // ä¸­é—´ç»“æœï¼šæ›´æ–°ä¸´æ—¶ä¸­é—´ç»“æœ
      interimResultRef.current = text;
      
      // æ›´æ–°æ˜¾ç¤º
      setResult(text);
      
      console.log('ä¸­é—´ç»“æœ:', interimResultRef.current);
    }
  };

  // æ™ºèƒ½éŸ³é¢‘æ´»åŠ¨æ£€æµ‹
  const detectAudioActivity = (inputData, maxAmplitude) => {
    // æ–¹æ³•1: åŸºäºæœ€å¤§æŒ¯å¹…çš„æ£€æµ‹
    if (maxAmplitude > 0.005) {
      return true;
    }
    
    // æ–¹æ³•2: åŸºäºRMS(å‡æ–¹æ ¹)çš„æ£€æµ‹
    let sum = 0;
    for (let i = 0; i < inputData.length; i++) {
      sum += inputData[i] * inputData[i];
    }
    const rms = Math.sqrt(sum / inputData.length);
    if (rms > 0.002) {
      return true;
    }
    
    return false;
  };

  // å¼€å§‹å½•éŸ³
  const startListening = async () => {
    if (disabled || isListening) {
      return;
    }

    try {
      setErrorMessage('');
      setResult('');
      finalResultRef.current = ''; // é‡ç½®ç´¯ç§¯ç»“æœ
      interimResultRef.current = ''; // é‡ç½®ä¸­é—´ç»“æœ
      isStoppingRef.current = false;
      audioBufferRef.current = [];
      lastAudioTimeRef.current = Date.now();
      sessionStartTimeRef.current = Date.now();
      
      // æ¸…ç†ä¹‹å‰çš„å®šæ—¶å™¨
      if (sendTimerRef.current) {
        clearInterval(sendTimerRef.current);
        sendTimerRef.current = null;
      }
      
      if (silenceTimerRef.current) {
        clearInterval(silenceTimerRef.current);
        silenceTimerRef.current = null;
      }
      
      // è·å–ç”¨æˆ·åª’ä½“æƒé™
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      });
      streamRef.current = stream;
      
      // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
      const AudioContext = window.AudioContext || window.webkitAudioContext;
      audioContextRef.current = new AudioContext({
        sampleRate: 16000
      });
      
      // ç¡®ä¿éŸ³é¢‘ä¸Šä¸‹æ–‡æ­£åœ¨è¿è¡Œ
      if (audioContextRef.current.state === 'suspended') {
        await audioContextRef.current.resume();
      }
      
      // åˆ›å»ºéŸ³é¢‘æºèŠ‚ç‚¹
      audioSourceRef.current = audioContextRef.current.createMediaStreamSource(stream);
      
      // åˆ›å»ºScriptProcessorèŠ‚ç‚¹
      audioProcessorRef.current = audioContextRef.current.createScriptProcessor(4096, 1, 1);
      
      // è®¾ç½®éŸ³é¢‘å¤„ç†å›è°ƒ
      audioProcessorRef.current.onaudioprocess = (event) => {
        if (!isStoppingRef.current && speechServiceRef.current?.isConnected) {
          const inputData = event.inputBuffer.getChannelData(0);
          
          // æ£€æŸ¥éŸ³é¢‘è¾“å…¥å¼ºåº¦
          let maxAmplitude = 0;
          for (let i = 0; i < inputData.length; i++) {
            const amplitude = Math.abs(inputData[i]);
            maxAmplitude = Math.max(maxAmplitude, amplitude);
          }
          
          // æ›´æ–°éŸ³é¢‘å¼ºåº¦æ˜¾ç¤º
          setAudioLevel(maxAmplitude * 100);
          
          // æ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘è¾“å…¥
          const hasAudio = detectAudioActivity(inputData, maxAmplitude);
          if (hasAudio) {
            lastAudioTimeRef.current = Date.now();
          }
          
          // è½¬æ¢ä¸º16ä½æ•´æ•°æ•°ç»„
          const pcmData = new Int16Array(inputData.length);
          for (let i = 0; i < inputData.length; i++) {
            const sample = Math.max(-1, Math.min(1, inputData[i]));
            pcmData[i] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
          }
          
          // å°†éŸ³é¢‘æ•°æ®æ·»åŠ åˆ°ç¼“å†²åŒº
          audioBufferRef.current.push(...pcmData);
        }
      };
      
      // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
      audioSourceRef.current.connect(audioProcessorRef.current);
      audioProcessorRef.current.connect(audioContextRef.current.destination);
      
      // è®¯é£APIå‡­è¯
      const XF_CONFIG = {
        appId: 'f7ae70c1',
        apiKey: '557206bc97aa567d51c22e37e2faa9b2',
        apiSecret: 'NTdmOGIyNjU3MWNkYzQzOGNmNWFjZGNi'
      };
      
      // è¿æ¥è®¯é£æœåŠ¡
      await speechServiceRef.current.connect(XF_CONFIG);
      
      // å‘é€ç¬¬ä¸€å¸§
      speechServiceRef.current.sendInitialFrame();
      
      // å¯åŠ¨å®šæ—¶å‘é€éŸ³é¢‘æ•°æ®
      startSendingAudio();
      
      // å¯åŠ¨æ™ºèƒ½é™éŸ³æ£€æµ‹
      startSmartSilenceDetection();
      
      setIsListening(true);
    } catch (err) {
      console.error('å¯åŠ¨å½•éŸ³å¤±è´¥:', err);
      const errorMsg = 'å¯åŠ¨å½•éŸ³å¤±è´¥: ' + (err.message || 'æœªçŸ¥é”™è¯¯');
      setErrorMessage(errorMsg);
      onError && onError(new Error(errorMsg));
      // stopListening();
    }
  };

  // å¯åŠ¨å®šæ—¶å‘é€éŸ³é¢‘æ•°æ®
  const startSendingAudio = () => {
    sendTimerRef.current = setInterval(() => {
      if (audioBufferRef.current.length >= 1280 && speechServiceRef.current?.isConnected) {
        const frameData = audioBufferRef.current.splice(0, 1280);
        const bytes = new Uint8Array(new Int16Array(frameData).buffer);
        
        let binary = '';
        for (let i = 0; i < bytes.byteLength; i++) {
          binary += String.fromCharCode(bytes[i]);
        }
        const base64Data = btoa(binary);
        
        speechServiceRef.current.sendAudioData(base64Data);
      }
    }, 40);
  };

  // å®šæ—¶æ—¥å¿—è®°å½•ï¼ˆä¸å†è‡ªåŠ¨åœæ­¢å½•éŸ³ï¼‰
  const startSmartSilenceDetection = () => {
    silenceTimerRef.current = setInterval(() => {
      if (!isListening) return;
      
      const now = Date.now();
      const timeSinceLastAudio = now - lastAudioTimeRef.current;
      const totalSessionTime = now - sessionStartTimeRef.current;
      
      console.log('å½•éŸ³çŠ¶æ€ç›‘æ§ - ä¼šè¯æ—¶é•¿:', Math.round(totalSessionTime/1000), 'ç§’, æœ€åéŸ³é¢‘è¾“å…¥:', Math.round(timeSinceLastAudio/1000), 'ç§’å‰');
    }, 5000);
  };

  // åœæ­¢å½•éŸ³
  const stopListening = () => {
    if (isStoppingRef.current) return;
    
    isStoppingRef.current = true;
    setIsListening(false);
    
    // æ¸…ç†å®šæ—¶å™¨
    if (sendTimerRef.current) {
      clearInterval(sendTimerRef.current);
      sendTimerRef.current = null;
    }
    
    if (silenceTimerRef.current) {
      clearInterval(silenceTimerRef.current);
      silenceTimerRef.current = null;
    }
    
    // ç¡®ä¿æ‰€æœ‰ä¸­é—´ç»“æœéƒ½è¢«åˆå¹¶åˆ°æœ€ç»ˆç»“æœä¸­
    if (interimResultRef.current) {
      finalResultRef.current = (finalResultRef.current || '') + interimResultRef.current;
      interimResultRef.current = '';
      // æ›´æ–°UIæ˜¾ç¤º
      setResult(finalResultRef.current);
    }
    
    // å‘é€å‰©ä½™éŸ³é¢‘æ•°æ®
    if (speechServiceRef.current?.isConnected) {
      // å‘é€ç¼“å†²åŒºä¸­å‰©ä½™çš„éŸ³é¢‘æ•°æ®
      while (audioBufferRef.current.length >= 1280) {
        const frameData = audioBufferRef.current.splice(0, 1280);
        const bytes = new Uint8Array(new Int16Array(frameData).buffer);
        let binary = '';
        for (let i = 0; i < bytes.byteLength; i++) {
          binary += String.fromCharCode(bytes[i]);
        }
        const base64Data = btoa(binary);
        speechServiceRef.current.sendAudioData(base64Data);
      }
      
      // å‘é€æœ€åä¸è¶³ä¸€å¸§çš„æ•°æ®
      if (audioBufferRef.current.length > 0) {
        const remainingData = new Int16Array(audioBufferRef.current);
        const bytes = new Uint8Array(remainingData.buffer);
        let binary = '';
        for (let i = 0; i < bytes.byteLength; i++) {
          binary += String.fromCharCode(bytes[i]);
        }
        const base64Data = btoa(binary);
        speechServiceRef.current.sendAudioData(base64Data);
        audioBufferRef.current = [];
      }
      
      // å‘é€ç»“æŸå¸§
      setTimeout(() => {
        if (speechServiceRef.current?.isConnected) {
          speechServiceRef.current.sendEndFrame();
        }
      }, 100);
    }
    
    // æ–­å¼€éŸ³é¢‘è¿æ¥
    cleanupAudioResources();
    
    // åœ¨å½•éŸ³å®Œå…¨ç»“æŸåï¼Œå°†æœ€ç»ˆç»“æœä¼ é€’ç»™çˆ¶ç»„ä»¶
      setTimeout(() => {
        if (finalResultRef.current) {
          console.log('è¯­éŸ³è¾“å…¥ç»“æŸï¼Œä¼ é€’æœ€ç»ˆç»“æœç»™çˆ¶ç»„ä»¶:', finalResultRef.current);
          // è®¾ç½®isReplaceä¸ºfalseï¼Œç¡®ä¿çˆ¶ç»„ä»¶å°†è¯†åˆ«ç»“æœè¿½åŠ åˆ°è¾“å…¥æ¡†å†…å®¹åé¢
          onResult && onResult(finalResultRef.current, false);
        } else {
          console.log('æ²¡æœ‰è¯†åˆ«åˆ°è¯­éŸ³å†…å®¹');
        }
        
        isStoppingRef.current = false;
      }, 200);
  };

  // æ¸…ç†éŸ³é¢‘èµ„æº
  const cleanupAudioResources = () => {
    // æ–­å¼€éŸ³é¢‘å¤„ç†å™¨è¿æ¥
    if (audioProcessorRef.current) {
      try {
        audioProcessorRef.current.disconnect();
      } catch (e) {
        console.warn('æ–­å¼€éŸ³é¢‘å¤„ç†å™¨æ—¶å‡ºé”™:', e);
      }
      audioProcessorRef.current = null;
    }
    
    // æ–­å¼€éŸ³é¢‘æºè¿æ¥
    if (audioSourceRef.current) {
      try {
        audioSourceRef.current.disconnect();
      } catch (e) {
        console.warn('æ–­å¼€éŸ³é¢‘æºæ—¶å‡ºé”™:', e);
      }
      audioSourceRef.current = null;
    }
    
    // åœæ­¢éŸ³é¢‘æµ
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => {
        track.stop();
      });
      streamRef.current = null;
    }
    
    // å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡
    if (audioContextRef.current) {
      audioContextRef.current.close().catch(e => {
        console.warn('å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡æ—¶å‡ºé”™:', e);
      });
      audioContextRef.current = null;
    }
  };

  // æµ‹è¯•éº¦å…‹é£
  const testMicrophone = async () => {
    if (isTestingMic) return;
    
    try {
      setIsTestingMic(true);
      setTestMicLevel(0);
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1
        } 
      });
      
      const AudioContext = window.AudioContext || window.webkitAudioContext;
      const audioContext = new AudioContext({
        sampleRate: 16000
      });
      
      const source = audioContext.createMediaStreamSource(stream);
      const processor = audioContext.createScriptProcessor(4096, 1, 1);
      
      processor.onaudioprocess = (event) => {
        const inputData = event.inputBuffer.getChannelData(0);
        let maxAmplitude = 0;
        for (let i = 0; i < inputData.length; i++) {
          maxAmplitude = Math.max(maxAmplitude, Math.abs(inputData[i]));
        }
        setTestMicLevel(maxAmplitude * 100);
      };
      
      source.connect(processor);
      processor.connect(audioContext.destination);
      
      // 5ç§’ååœæ­¢æµ‹è¯•
      setTimeout(() => {
        try {
          processor.disconnect();
          source.disconnect();
          stream.getTracks().forEach(track => track.stop());
          audioContext.close();
        } catch (e) {
          console.warn('æ¸…ç†æµ‹è¯•èµ„æºæ—¶å‡ºé”™:', e);
        }
        setIsTestingMic(false);
        setTestMicLevel(0);
      }, 5000);
      
    } catch (err) {
      console.error('éº¦å…‹é£æµ‹è¯•å¤±è´¥:', err);
      setErrorMessage('éº¦å…‹é£æµ‹è¯•å¤±è´¥: ' + err.message);
      setIsTestingMic(false);
      setTestMicLevel(0);
    }
  };

  // åˆ‡æ¢å½•éŸ³çŠ¶æ€
  const toggleListening = () => {
    if (isListening) {
      stopListening();
    } else {
      startListening();
    }
  };

  // æ¸…ç©ºç»“æœ
  const clearResult = () => {
    finalResultRef.current = '';
    interimResultRef.current = '';
    setResult('');
    setErrorMessage('');
  };

  return (
    <div className={`speech-recognition ${className}`}>
      <div className="speech-controls">
        <button
          type="button"
          className={`speech-button ${isListening ? 'listening' : ''} ${disabled ? 'disabled' : ''}`}
          onClick={toggleListening}
          disabled={disabled || isTestingMic}
        >
          {isListening ? 'â¹ï¸ åœæ­¢å½•éŸ³' : 'ğŸ¤ è¯­éŸ³è¾“å…¥'}
        </button>
        
        <button
          type="button"
          className="test-microphone-button"
          onClick={testMicrophone}
          disabled={isListening || isTestingMic}
        >
          {isTestingMic ? 'æµ‹è¯•ä¸­...' : 'ğŸ”§ æµ‹è¯•éº¦å…‹é£'}
        </button>
        
        {result && (
          <button
            type="button"
            className="clear-button"
            onClick={clearResult}
            title="æ¸…ç©ºç»“æœ"
            disabled={isListening}
          >
            ğŸ—‘ï¸
          </button>
        )}
      </div>
      
      {isListening && (
        <div className="audio-level-indicator">
          <div className="audio-level-label">
            ğŸ¤ éŸ³é‡: {audioLevel.toFixed(0)}% 
            {audioLevel > 5 ? ' ğŸ”Š' : audioLevel > 1 ? ' ğŸ”‰' : ' ğŸ”ˆ'}
          </div>
          <div className="audio-level-bar">
            <div 
              className="audio-level-fill" 
              style={{ 
                width: `${Math.min(audioLevel * 3, 100)}%`,
                backgroundColor: audioLevel > 10 ? '#4CAF50' : audioLevel > 5 ? '#FFC107' : '#FF5722'
              }}
            ></div>
          </div>
        </div>
      )}
      
      {isTestingMic && (
        <div className="audio-level-indicator test-mic-indicator">
          <div className="audio-level-label">
            ğŸ”§ æµ‹è¯•éº¦å…‹é£: {testMicLevel.toFixed(0)}% 
            {testMicLevel > 5 ? ' ğŸ”Š' : testMicLevel > 1 ? ' ğŸ”‰' : ' ğŸ”ˆ'}
          </div>
          <div className="audio-level-bar">
            <div 
              className="audio-level-fill" 
              style={{ 
                width: `${Math.min(testMicLevel * 3, 100)}%`,
                backgroundColor: testMicLevel > 10 ? '#4CAF50' : testMicLevel > 5 ? '#FFC107' : '#FF5722'
              }}
            ></div>
          </div>
        </div>
      )}
      
      {errorMessage && (
        <div className="speech-error">
          <span>{errorMessage}</span>
          <button 
            type="button" 
            className="clear-error-btn"
            onClick={() => setErrorMessage('')}
          >
            âœ•
          </button>
        </div>
      )}
        
        {/* è¯†åˆ«ç»“æœæ¡† - ä»…ç”¨äºç•Œé¢é¢„è§ˆï¼Œä¸ä¼šä¼ é€’ç»™çˆ¶ç»„ä»¶ */}
        {result && (
          <div className="speech-result">
            <div className="result-label">è¯†åˆ«é¢„è§ˆï¼š</div>
            <div className="result-text">{result}</div>
            <div className="result-note">ï¼ˆé¢„è§ˆå†…å®¹ï¼Œåœæ­¢å½•éŸ³åæ‰ä¼šå¡«å…¥è¾“å…¥æ¡†ï¼‰</div>
          </div>
        )}
        
        {isListening && (
        <div className="voice-recording-indicator">
          æ­£åœ¨å½•éŸ³...è¯·ç»§ç»­è¯´è¯ (è¯·ç‚¹å‡»åœæ­¢æŒ‰é’®ç»“æŸå½•éŸ³)
        </div>
      )}
      
      <div className="speech-tips">
        <p>ğŸ’¡ ä½¿ç”¨æç¤ºï¼š</p>
        <ul>
          <li>è¯·ç¡®ä¿éº¦å…‹é£æƒé™å·²å¼€å¯</li>
          <li>å»ºè®®åœ¨å®‰é™ç¯å¢ƒä¸­ä½¿ç”¨ï¼Œæ•ˆæœæ›´ä½³</li>
          <li>æ”¯æŒä¸­æ–‡æ™®é€šè¯è¯†åˆ«</li>
          <li>è¯·ç‚¹å‡»åœæ­¢æŒ‰é’®æ‰‹åŠ¨ç»“æŸå½•éŸ³</li>
        </ul>
      </div>
    </div>
  );
};

export default SpeechRecognition;